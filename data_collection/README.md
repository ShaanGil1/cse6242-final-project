### data_retrieval.ipynb
Requirements: \
python==3.7 \
jupyter==1.0.0 \
pandas==1.1.0 \
tweetpy==(most recent version)

Run all the import cells to make sure you have the all needed packages. And copy paste personal twitter keys into appropriate cell block.\
Clone the following github repo:\
https://github.com/shaypal5/awesome-twitter-data

Select the time frame of data that needs to be gather by deleting data that doesn't need to be gathered. The first half the file will compile the data from the github repo and the second half will use the tweet ids to retrive all the data.  The following 4 paths need to be adjusted on the notebook to match the machine that is running the file:\
-Root path of all the data that is in being collect (data pulled from github repo)\
-Path of where compiled data will be stored\
-Path of compiled data (same as one above)\
-Path of where all twitter data will be stored\

This file will pull the fields that we found relavant to our project however they can be adjusted if other fields need to be pulled.

### Data_cleanup.ipynb
Requirements: \
python==3.7 \
jupyter==1.0.0 \
numpy==1.19.1 \
pandas==1.1.0 

All sections (marked by v# in the first cell) can be run by running the import cell at the top then running the cells 1 by 1, assuming you have the necessary .csv file from the cdc website:\
https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-Jurisdi/unsk-b7fc/data 

our google drive:\
https://drive.google.com/drive/folders/1jmqrrgiNyqUFemB4LCvO1LK7Uyl2nnd-?usp=share_link 
or generated by an earlier section. 
Paths should function in a way that's system agnostic if you place everything in the data_collection folder.  
